ğŸ“‹ Project Overview
Project Title: Investigating Brute Force Attacks Using SIEM Logs (Splunk/ELK)
This project implements a complete machine learning pipeline for detecting HTTPS brute force attacks using network flow analysis. The system achieves 99.96% accuracy with Random Forest classification and provides full integration capabilities with SIEM systems like Splunk and ELK Stack.

ğŸ¯ Key Results
Model	ROC-AUC	F1-Score	Accuracy	Errors (out of 13,494)
Logistic Regression	0.9963	0.9323	98.23%	334 errors
Random Forest	1.0000	0.9989	99.96%	5 errors
Best Model: Random Forest with only 1 false positive and 4 false negatives.

ğŸ“ Project Structure
text
brute_force_detection/
â”œâ”€â”€ run_full_pipeline.py          # Main execution script
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ data_preprocessing.py     # Complete data preprocessing
â”‚   â”œâ”€â”€ model_training.py         # Model training and evaluation
â”‚   â”œâ”€â”€ siem_log_generator.py     # SIEM integration utilities
â”‚   â””â”€â”€ utils.py                  # Helper functions
â”œâ”€â”€ notebooks/
â”‚   â””â”€â”€ 02_data_exploration_fixed.py  # EDA and analysis
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ config.py                 # Project configuration
â”‚   â”œâ”€â”€ elk_index_template.json   # ELK Stack configuration
â”‚   â””â”€â”€ splunk_config.json        # Splunk configuration
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ raw/                      # Original dataset
â”‚   â”œâ”€â”€ processed/                # Cleaned and split data
â”‚   â””â”€â”€ siem_logs/                # SIEM-formatted logs
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ baseline_model.pkl        # Logistic Regression model
â”‚   â”œâ”€â”€ advanced_model.pkl        # Random Forest model
â”‚   â””â”€â”€ model_results_summary.json # Performance metrics
â”œâ”€â”€ reports/
â”‚   â”œâ”€â”€ FINAL_REPORT.md           # Comprehensive project report
â”‚   â”œâ”€â”€ confusion_matrix_*.png    # Model evaluation visuals
â”‚   â””â”€â”€ roc_curves_comparison.png # ROC comparison
â”œâ”€â”€ requirements.txt              # Python dependencies
â””â”€â”€ README.md                     # This file
ğŸš€ Quick Start
1. Prerequisites
Python 3.8 or higher

4GB+ RAM

2GB+ free disk space

2. Installation
bash
# Clone the repository
git clone https://github.com/yourusername/brute_force_detection.git
cd brute_force_detection

# Create virtual environment
python -m venv venv

# Activate virtual environment
# Windows:
venv\Scripts\activate
# Mac/Linux:
source venv/bin/activate

# Install dependencies
pip install -r requirements.txt
3. Download Dataset
Visit: https://zenodo.org/records/7227413

Download samples.csv

Place it in: data/raw/https_bruteforce_samples.csv

4. Run Complete Pipeline
bash
# Run the complete ML pipeline
python run_full_pipeline.py
The pipeline will:

Preprocess data (handle missing values, scale features)

Train both Logistic Regression and Random Forest models

Evaluate models with comprehensive metrics

Generate visualizations and reports

Create SIEM-compatible log formats

ğŸ“Š Dataset Information
Dataset: HTTPS Brute-force dataset with extended network flows
Source: Zenodo (https://zenodo.org/records/7227413)
Size: 67,469 samples, 61 features
Classes:

Benign (Class 0): 55,822 samples (82.7%)

Attack (Class 1): 11,647 samples (17.3%)

Attack Tools: Ncrack, Thc-hydra, Patator
Target Applications: WordPress, Joomla, MediaWiki, Apache, Nginx, and 6 more

ğŸ”§ Technical Implementation
Data Preprocessing Pipeline
Loading: Read CSV data with pandas

Cleaning: Handle missing values (TLS_SNI, TLS_JA3 - 16.5% missing)

Feature Selection: Remove irrelevant features (IPs, timestamps)

Scaling: StandardScaler for normalization

Splitting: 80/20 train/test split with stratification

Imbalance Handling: Class weighting and stratified sampling

Models Implemented
1. Baseline Model: Logistic Regression
Purpose: Establish performance baseline

Hyperparameters: C=10, solver='liblinear' (optimized via GridSearchCV)

Class Weighting: 'balanced' to handle 4.79:1 imbalance

2. Advanced Model: Random Forest
Purpose: High-accuracy production model

Hyperparameters: n_estimators=200, max_depth=None (optimized via GridSearchCV)

Advantages: Handles non-linear patterns, robust to noise

Evaluation Metrics
Primary: ROC-AUC, F1-Score (for imbalanced data)

Secondary: Precision, Recall, Accuracy

Visualizations: Confusion matrices, ROC curves, feature importance

ğŸ”— SIEM Integration
ELK Stack Integration
Log Format: JSON Lines (JSONL) compatible with Elasticsearch

Index Template: Provided in config/elk_index_template.json

Visualization: Ready for Kibana dashboards

Fields: Timestamp, source IP, destination IP, ML predictions, confidence scores

Splunk Integration
Log Format: CSV with proper field extraction

Configuration: Provided in config/splunk_config.json

SPL Queries: Pre-built search queries for threat hunting

Alerts: Configurable alerting based on ML predictions

Sample Integration Code
python
# Real-time prediction and SIEM integration
from src.model_training import ModelTrainer
import json

# Load trained model
trainer = ModelTrainer()
model = trainer.load_model('models/advanced_model.pkl')

# Predict on new logs
predictions = model.predict(new_network_data)

# Send to SIEM
def send_to_siem(log_entry, prediction):
    siem_log = {
        **log_entry,
        'ml_prediction': prediction,
        'ml_confidence': model.predict_proba([log_entry])[0][1]
    }
    # Send to ELK or Splunk
ğŸ“ˆ Performance Analysis
Confusion Matrix (Random Forest)
text
              Predicted
              Benign   Attack
Actual Benign  11164      1   (99.99% correct)
Actual Attack     4    2325   (99.83% correct)
Error Analysis
Total Test Samples: 13,494

Random Forest Errors: 5 (0.037%)

False Positives: 1 (0.007%) - minimal false alarms

False Negatives: 4 (0.030%) - minimal missed attacks

ğŸ“ Usage Examples
1. Data Exploration
bash
python notebooks/02_data_exploration_fixed.py
2. Train Models Only
python
from src.model_training import ModelTrainer

trainer = ModelTrainer()
results = trainer.train_and_evaluate()
3. Generate SIEM Logs
bash
python src/siem_log_generator.py
4. Make Predictions on New Data
python
import joblib
import pandas as pd

# Load model and scaler
model = joblib.load('models/advanced_model.pkl')
scaler = joblib.load('data/processed/scaler.pkl')

# Preprocess new data
new_data = pd.read_csv('new_network_logs.csv')
new_data_scaled = scaler.transform(new_data)

# Make predictions
predictions = model.predict(new_data_scaled)
probabilities = model.predict_proba(new_data_scaled)
ğŸ“ Academic Requirements Met
This project fulfills all requirements from the "Machine Learning Semester Project â€“ Student Instructions":

Requirement	Status	Notes
Problem Understanding	âœ… Complete	Clear objective, importance explained
Data Collection	âœ… Complete	High-quality public dataset used
Data Preprocessing	âœ… Complete	Full preprocessing pipeline
Exploratory Data Analysis	âœ… Complete	Statistical summaries and visualizations
Model Development	âœ… Complete	Two models: baseline and advanced
Model Evaluation	âœ… Complete	Comprehensive metrics and comparison
Discussion & Conclusion	âœ… Complete	Results interpretation and limitations
All Deliverables	âœ… Complete	Code, report, presentation, GitHub repo

ğŸ“„ Deliverables
Project Code: Complete, well-commented Python implementation

Cleaned Dataset: Processed training and test data

Final Report: 10+ page comprehensive report (reports/FINAL_REPORT.md)

Presentation Materials: Visualizations and summary slides

Trained Models: Serialized Logistic Regression and Random Forest

SIEM Integration: Configurations for ELK and Splunk
